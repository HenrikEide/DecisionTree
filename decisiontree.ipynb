{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple, List\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import time as t"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "source": [
    "def split_data(data, split_percent):\n",
    "    test_data = data.sample(frac=split_percent)\n",
    "    training_data = data.drop(test_data.index)\n",
    "    x_test = test_data.to_numpy()[:,0:10]\n",
    "    x_train = training_data.to_numpy()[:,0:10]\n",
    "    y_test = test_data.to_numpy()[:,10]\n",
    "    y_train = training_data.to_numpy()[:,10]\n",
    "\n",
    "    return x_train, x_test, y_train, y_test"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "source": [
    "df = pd.read_csv(\"magic04.data\")\n",
    "\n",
    "X = df.to_numpy()[:,0:10]\n",
    "Y = df.to_numpy()[:,10]\n",
    "\n",
    "\n",
    "## X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.75)\n",
    "X_train, X_test, Y_train, Y_test = split_data(df, 0.75)\n",
    "print(\"\\nX_train:\", X_train, \"\\nX_test:\", X_test, \"\\nY_train:\", Y_train, \"\\nY_test:\", Y_test)\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "sample() got an unexpected keyword argument 'freq'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_352932/905370376.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m## X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.75)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nX_train:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\nX_test:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\nY_train:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\nY_test:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_352932/3339022017.py\u001b[0m in \u001b[0;36msplit_data\u001b[0;34m(data, split_percent)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msplit_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_percent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit_percent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtraining_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: sample() got an unexpected keyword argument 'freq'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test = X_train[:,1]\n",
    "test2 = X_train\n",
    "# print(sorted(test))\n",
    "print(type(X_train[0,0]))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'float'>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "En kolonne med en verdi for hver rad, hvor mange kilo bifangst av den arten for den turen per rekevekt for den samme turen. -> oversikt per kvartal, slå samme alle de av samme art. Men da summerer den opp de vektene, og det blir feil da vil jeg få et feil bilde?!?!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def getLabelSplitAvg(X : np.ndarray, y : list, col : int) -> Tuple[list, list]:\n",
    "    xAvg = np.sum(X[:][col])/len(y)\n",
    "    aboveEq = []\n",
    "    below = []\n",
    "    for i in range(len(y)):\n",
    "        if X[i][col] >= xAvg:\n",
    "            aboveEq.append(y[i])\n",
    "        else:\n",
    "            below.append(y[i])\n",
    "    return (aboveEq, below)\n",
    "\n",
    "def getLabelSplitAvgX(X : np.ndarray, y : list, col : int) -> Tuple[list, list]:\n",
    "    xAvg = np.sum(X[:][col])/len(y)\n",
    "    aboveEq = []\n",
    "    below = []\n",
    "    for i in range(len(y)):\n",
    "        if X[i][col] >= xAvg:\n",
    "            aboveEq.append(X[i])\n",
    "        else:\n",
    "            below.append(X[i])\n",
    "    return (aboveEq, below)\n",
    "# getLabelSplitAvg(X_train, Y_train, 0)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def entropy(y):\n",
    "    if len(y) == 0:\n",
    "        return 0\n",
    "    probOfG = list(y).count('g')/(len(y)) \n",
    "    probOfH = 1 - probOfG\n",
    "    if probOfG == 1 or probOfG == 0:\n",
    "        return probOfG\n",
    "    return (-1) * (probOfG * np.log2(probOfG) + (probOfH) * np.log2(probOfH))\n",
    "\n",
    "def entropySplit(X : List[list], y : list):\n",
    "    yEntropy = entropy(y)\n",
    "    allEnt = []\n",
    "    for col in range(len(X[0])):\n",
    "        aboveEq, below = getLabelSplitAvg(X, y, col)\n",
    "        allEnt.append(yEntropy - entropy(aboveEq)*len(aboveEq)/len(y) + entropy(below)*len(aboveEq)/len(y))\n",
    "    return allEnt.index(max(allEnt))\n",
    "    \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def gini_index(y):\n",
    "    probOfG = list(y).count('g')/(len(y))\n",
    "    if not y:\n",
    "        return 1\n",
    "    return  -probOfG * (1-(probOfG)) -(1-probOfG) * (1-(1-probOfG))\n",
    "\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Entropy:\",entropy(['g','h','g','h','g','h','g','h','g','h','g','h','g','h','g','h','g','h','g','h','h','h','h','h','h','h']))\n",
    "print(\"Gini index:\",gini_index(['g','h','g','h','g','h','g','h','g','h','g','h','g','h','g','h','g','h','g','h','h','h','h','h','h','h']))\n",
    "print(\"Gini index test:\",gini_index(['g','g','g','g','g','g','g','g','g','g']))\n",
    "print(\"Gini index test 2:\",gini_index(['g','h']))\n",
    "print(\"Entropy test:\",entropy(['g','g','g','g','g','g','g','g','g','g',]))\n",
    "print(\"Entropy test 2:\",entropy(['g','h',]))\n",
    "\n",
    "print(\"Entropy split:\",entropySplit(X_train, Y_train))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Entropy: 0.9612366047228759\n",
      "Gini index: -0.47337278106508873\n",
      "Gini index test: -0.0\n",
      "Gini index test 2: -0.5\n",
      "Entropy test: 1.0\n",
      "Entropy test 2: 1.0\n",
      "Entropy split: 6\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "def learn(X, y):\n",
    "    if len(set(y))-1==1:\n",
    "        return y[0]\n",
    "\n",
    "    elif all(list(map(lambda x: all(list(map(lambda y: X[0][0]==y, x))), list(X)))):\n",
    "        return 'g' if list(y).count('g')>(len(y)-1/2) else 'h'\n",
    "    \n",
    "    else:\n",
    "        splitIndex = entropySplit(X,y)\n",
    "        x1, x2 = getLabelSplitAvgX(X, y, splitIndex)\n",
    "        y1, y2 = getLabelSplitAvg(X, y, splitIndex)\n",
    "\n",
    "        return (learn(x1, y1), learn(x2, y2), splitIndex, np.sum(X[:, splitIndex])/len(y)-1)\n",
    "\n",
    "# tree = learn(X, y)\n",
    "# predict(new_x, tree)\n",
    "\n",
    "t = learn(X_test,Y_test)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def predict(x, tree):\n",
    "    if tree in ['g', 'h']:\n",
    "        return tree\n",
    "    else:\n",
    "        splitIndex = tree[2]\n",
    "        avg = tree[3]\n",
    "        return predict(x, tree[0]) if x[splitIndex] >= avg else predict(x, tree[1])\n",
    "\n",
    "#g = learn(X_train, Y_train)\n",
    "#print(predict([36.1741,17.6865,2.946,0.2865,0.1591,-4.7746,-18.9697,11.3256,0.254,191.455], g))\n",
    "\n",
    "print(predict(X_train[0],t))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "g\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}