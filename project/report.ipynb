{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Project 1: Decision Tree Implementation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1 Greedy learning decision tree algorithm\r\n",
    "\r\n",
    "The decision tree learns by splitting data from one node into two based on the values of a single attribute of the given data at a time, until either a consesus about the class label is reached or the data points are all equal, at which point the algorithm cannot learn more from the data.<br>\r\n",
    "### Prerequisite:\r\n",
    "The algorithm assumes that all data point values are floating point numbers or integers, and the class labels are strings.\r\n",
    "### Steps:\r\n",
    "1. Receive node, with all data values and class label list. \r\n",
    "2. If all class labels are equal, that label is chosen, and the node is a leaf, which means no more steps are taken for this node.<br>\r\n",
    "    Else if all data points have the same values in each column, the most common label is chosen, and the node is a leaf.<br>\r\n",
    "    Else continue the algorithm with this node.\r\n",
    "3. Choose the attribute, or column, with highest information gain available. \r\n",
    "4. Split the rows of data and the class labels on the average value in the chosen column.\r\n",
    "5. Run the algorithm recursively with both new nodes.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Our implementation.\r\n",
    "\r\n",
    "We use the dataclasses module for simpler class definitions. The algorithm is split into three dataclasses, `tree`, `node` and `data`. The class `data` is a simple class containing lists of the data split into both test and train data and further into feature values and class labels. `node` contains all the information needed to find out if the node is a leaf or if it should be split further, as well as information needed later when building the tree and predicting the class label of new data points. For example it's child nodes, if any. `tree` contains all the logic for building the tree, or, if you will, training the algorithm. "
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit"
  },
  "interpreter": {
   "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}