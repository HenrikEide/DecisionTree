{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Project 1: Decision Tree Implementation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1 Greedy learning decision tree algorithm\r\n",
    "\r\n",
    "The decision tree learns by splitting data from one node into two based on the values of a single attribute of the given data at a time, until either a consesus about the class label is reached or the data points are all equal, at which point the algorithm cannot learn more from the data.<br>\r\n",
    "### Prerequisite:\r\n",
    "The algorithm assumes that all data point values are floating point numbers or integers, and the class labels catagorical variables, strings.\r\n",
    "### Steps:\r\n",
    "1. Receive node, with all data values and class label list. \r\n",
    "2. If all class labels are equal, that label is chosen, and the node is a leaf, which means no more steps are taken for this node.<br>\r\n",
    "    Else if all data points have the same values in each column, the most common label is chosen, and the node is a leaf.<br>\r\n",
    "    Else continue the algorithm with this node.\r\n",
    "3. Choose the attribute, or column, with highest information gain available. \r\n",
    "4. Split the rows of data and the class labels on the average value in the chosen column.\r\n",
    "5. Run the algorithm recursively with both new nodes.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Our implementation.\r\n",
    "\r\n",
    "We use the dataclasses module for simpler class definitions. The algorithm is split into three dataclasses, `Tree`, `Tode` and `Data`. The class `Data` is a simple class containing lists of the data split into both test and train data and further into feature values and class labels. `Node` contains all the information needed to find out if the node is a leaf or if it should be split further, as well as information needed later when building the tree and predicting the class label of new data points. For example it's child nodes, if any. `Tree` contains all the logic for building the tree, aka training the algorithm. Also included is the prediction and pruning functions, more on those later.\r\n",
    "\r\n",
    "### Impurity measure.\r\n",
    "\r\n",
    "Information gain is calculated using the change in entropy from before splitting to after the split, for each attribute, before deciding which column to split on. Entropy is a measure of uncertainty, is this case with two possible labels, 1 means that the labels are split 50-50 and 0 means that all class labels are the same. The impurity of each node is lowered as much as possible, which, most often, leads to overfitting. Meaning the algorithm is trained too well on the training data and will therefore perform worse on the test data. The entropy also relies on the probability of any label being chosen among the class labels, so a function to calculate this probability is included. The label you find the probability for does not matter, since, again,  there are only two possible labels and the entropy uses the probability of both of them."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 Gini index\r\n",
    "\r\n",
    "Added alternative impurity measure, the gini index, as a setting for choosing the best attribute to split the data on. Implemented a function to calculate the gini index which takes the sum of the square of both the probabilities (for each class label) and subtracts them from 1. Gini index is chosen as impurity measure by setting the `impurity_measure` parameter in `learn()` to `\"gini\"`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit"
  },
  "interpreter": {
   "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}